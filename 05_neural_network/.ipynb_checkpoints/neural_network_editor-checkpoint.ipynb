{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネット実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. データの特徴について確認します。（13問）\n",
    "    - 各変数のデータ型、行列数、統計量を算出し、今回扱うデータの外観を把握します。\n",
    "2. データを加工する方法について学習します。（7問）\n",
    "    - 各変数をモデルに入れる形に整えます。（特徴量生成フェーズ）\n",
    "3. ニューラルネットワークのモデリング方法について学習します。（19問）\n",
    "    - ディープラーニングのモデリングと精度を上げるときのポイントについて学習します。\n",
    "4. CNNについて学習します。（17問）\n",
    "    - 画像データに対して相性の良いCNNモデルについて学習します。\n",
    "5. RNNについて学習します。（15問）\n",
    "    - 時系列、テキストデータ等に対して相性の良いRNNモデルについて学習します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 事前準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1  必要なライブラリを読み込んで下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# 目的変数の加工処理で必要なライブラリ\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# Jupyter 上で図を表示するためのコマンド\n",
    "%matplotlib inline\n",
    "\n",
    "# warningを表示させない\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2 minstを読み込んで、学習データ（説明変数）、学習データ（目的変数）、検証データ（説明変数）、検証データ（目的変数）にデータを格納してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.データの特徴について確認します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1説明変数の学習データ（X_train）の レコード数を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 目的変数の学習データ（y_train）レコード数を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3（X_train）の行列数（各次元の要素数）を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 今回の学習データは3次元の性質を持っているようです。今度は正解データの性質を確認してみましょう。（y_train）の行列数を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 正解データは1次元です。X_trainの1番目（indexは0）のデータの中身を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 同様にy_trainのデータの中身を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 y_trainの要素の集計を行いましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5923\n",
       "1    6742\n",
       "2    5958\n",
       "3    6131\n",
       "4    5842\n",
       "5    5421\n",
       "6    5918\n",
       "7    6265\n",
       "8    5851\n",
       "9    5949\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8 目的変数は0～9までの数字が割り当てられているようです。説明変数と目的変数それぞれの学習データ、検証データの次元数を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.9 学習データは60000件、検証データは10000件、学習データの要素数は28×28、それに対して0～9の正解データが存在していることが分かりました。最初の学習データ（indexは0）を可視化してみましょう。※ヒント：「plt.imshow」を使用してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = X_train[0]\n",
    "plt.imshow(a, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.10 色の濃さはどのように表現されているのでしょうか。最初の学習データ（0番目）の最初の要素（0番目）を出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.11 最初の学習データ（indexは0）の6番目の要素（indexは5）を出力してください。※画像と数字を比較して見てください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "        18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "         0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.12 最初の学習データ（indexは0）を転置させて、6番目の要素（indexは5）を出力してください。※画像と数字を比較して見てください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 172, 253,   0,\n",
       "         0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].T[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.13 学習データの構成は（60000,28,28）＝（枚数,横座標,縦座標）を表しており、数字が小さいと「白」、大きいと「黒」を表現しているようです。最後にtrain_xの最大値、最小値を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.max())\n",
    "print(X_train.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.データの加工方法について学習します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 kerasに入れる形にデータを整えていきましょう。まず、28×28の画像データ（X_train,X_test）を全て（60000枚）1次元化してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 784)\n",
      "X_test: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 ディープラーニングは正規化処理を施した方が適切な結果が出ることが多いです。28×28の画像データ（X_train,X_test）の最大値が1になるように正規化してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_max: 1.0\n",
      "X_test_min: 0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "print(\"X_train_max:\",X_train.max())\n",
    "print(\"X_test_min:\",X_test.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 目的変数の形を「0」、「1」だけで表す必要があります。整数値を2値クラスの配列に変換した上で、y_trainを上から5行表示してください。※ワンホットエンコーディング処理といいます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "t_test = to_categorical(y_test, 10)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 説明変数と目的変数の形式は整いました。それでは各ノードにおける「入力」と「出力」のイメージを理解していきましょう。下記の様な「2×3」の行列を作成して、「w」と言う変数に格納して下さい。同様に「3×1」の行列を作成し、「x」という変数に格納して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 「3個のデータ」である「x」に重み「w」をかけ合わせて「2個のデータ」を出力してみましょう。※行列演算を行います。ニューラルネットワークはデータに重みをかけ合わせて新たな数値を出力し、その数値を活性化関数で変換して出てきた値を次の層の入力とすることの繰り返しです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 活性化関数のイメージを掴んでいきましょう。「2.5」で算出した行列に、活性化関数の一種である「シグモイド関数」をかけて値を算出して下さい。※値が0～1の間に収まる関数です。kerasでは引数で設定することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7 活性化関数のイメージを掴んでいきましょう。「2.5」で算出した行列に、活性化関数の一種である「relu」をかけて値を算出して下さい。※正の値はそのまま、負の値は「0」に変換する関数です。kerasでは引数で設定することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.ニューラルネットワークのモデリング方法について学習します。※layerの名前、精度結果が一致している必要は無いです。また、モデリングの実行後、時間がかかる処理があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Sequentialのクラスを読み込み、modelという変数に格納して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.engine.sequential.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "print(Sequential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 全結合レイヤーである「Dense」のクラスを読み込んで下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.layers.core.Dense'>\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "print(Dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 今回は「Sequentialモデル」を使用して、ニューラルネットワークを構築していきましょう。「784」件の入力を受け取り、「32」件の出力を返し、活性化関数が「シグモイド関数」の層を作成してください。※32件にしている理由は特にありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 32)                25120     \n",
      "=================================================================\n",
      "Total params: 25,120\n",
      "Trainable params: 25,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='sigmoid', input_dim=784))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 「10」件の出力を返す、活性化関数がソフトマックス関数の出力層を追加し、サマリーを出力して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 学習方法をcompile関数で設定しましょう。最適化関数を「確率的勾配降下法（Stochastic gradient descent）」を選択して下さい。誤差関数を「categorical_crossentoropy」で設定し、metricsは「正解率」を設定してみましょう。※何を目的として重みを更新するかを決定している部分になります。※確率的勾配降下法は難しい概念なので、本コンテンツでは説明しません。詳しく知りたい方は調べてみて下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 学習を実行しましょう。fit関数に学習データを当てはめて下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 511us/step - loss: 1.6217 - accuracy: 0.6315\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 「3.6」の学習を、epochs「4」で設定して行って下さい。※epochsとは「一つの訓練データを何回繰り返して学習させるか」の数のことです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1875/1875 [==============================] - 1s 524us/step - loss: 0.8768 - accuracy: 0.8192\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 1s 544us/step - loss: 0.6317 - accuracy: 0.8565\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 1s 588us/step - loss: 0.5205 - accuracy: 0.8750\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 1s 596us/step - loss: 0.4579 - accuracy: 0.8853\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(X_train, y_train, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8 学習を繰り返せば、精度が向上することが確認できます。「3.7」の学習を、batch_size=「100」で設定して行って下さい。※batchとは、訓練データをいくつかのかたまりに分割したものを指します。batch_sizeとはそのかたまりのサイズを指します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.4287 - accuracy: 0.8907: 0s - loss: 0.4328 - ac\n",
      "Epoch 2/4\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.4176 - accuracy: 0.8925\n",
      "Epoch 3/4\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.4076 - accuracy: 0.8941\n",
      "Epoch 4/4\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.3987 - accuracy: 0.8956\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(X_train, y_train, epochs=4, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9 学習速度が早くなっていることが確認できます。ディープラーニングは学習時間が非常にかかるので、データによっては速度を意識する必要があることを覚えておきましょう。学習データに対する結果を確認し、x軸に「epoch」、y軸に「accuracy」のグラフを作成して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.10 今度は検証データに対する評価結果を確認してみましょう。誤差と正解率を算出して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1224 test_function  *\n        return step_function(self, iterator)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1215 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1208 run_step  **\n        outputs = model.test_step(data)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1177 test_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-794c524bc0ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1224 test_function  *\n        return step_function(self, iterator)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1215 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1208 run_step  **\n        outputs = model.test_step(data)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1177 test_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy  = model.evaluate(X_test, y_test, verbose=False)\n",
    "print('loss:',loss)\n",
    "print('accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エラーが出たため、解答を確認しても同じエラーが出てしまう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.11 「3.8」の条件と、中間層を「1つ」追加した時と「2つ」追加した時の「モデルサマリ」、「正解率推移」、「評価指標」を確認して下さい。※今までの処理を関数化するイメージです。中間層の入力数と出力数は「32」で設定しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.12 層を増やせば増やすほど、学習データの精度が劣化していることが確認できました。次は「3.11」の「中間層を2層追加した状態」でエポック数を40回に設定し、学習データの精度の推移を確認して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.13 「3.12」の条件に加えてepochsを「10」で設定し、学習データと検証データの「誤差」の推移を確認してグラフを出力して下さい。※モデルを初期化する必要はないです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.14「学習データ」、「検証データ」共に、誤差が減少していることが分かります。複雑なモデルには、沢山の学習が必要なようです。今度は中間層無しで入力数を[32, 64, 128, 256]と変更したときの。学習データの精度を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.15 入力数を増やした結果、層を増やした結果より効果が得られました。モデルは複雑になり過ぎず、簡単になり過ぎず、様々な条件を試行して、良いバランスを目指す必要があります。活性化関数を「relu」に変更し、その他は「3.11」の条件で精度を確認してみて下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.16 活性化関数は「sigmoid」ではなく「relu」を使用した方が、一般的には良い精度が得られることが多いです。compileの最適化関数も変更してみましょう。「sgd」から「rmsprop」に変更して精度を確認して下さい。※データによって「最適なモデル」の条件は異なります。様々な観点で試行していくことが重要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.17 約90%程度正解率があるようです。「3.16」で作成したモデルで（X_test[0]）に対して予測結果を出力してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.18 配列のままだと少し分かりづらいので、結果をグラフ化してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.19 「7」と言う予測結果が出ています。「1.9」の方法で実際のデータの結果を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.CNNについて学習します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Sequentialのクラスを読み込み、modelという変数に格納して下さい。※先程作成したモデルが初期化されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fa271426490>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 CNNの入力は画像の形式のまま扱う必要があります。X_trainとX_testの形状を画像の形式に変更して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28, 1)\n",
      "X_test: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "print('X_train:',X_train.shape)\n",
    "print('X_test:',X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 CNNを構築していきましょう。先ずは活性化関数を「relu」に設定してコンボリューション層を追加し、summaryを出力して下さい。※ヒント：output shapeの形からストライド（移動する幅）の数を推定しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Conv2D(32, (3,3),activation='relu',input_shape=(28, 28, 1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 CNNはコンボリューション層とプーリング層を交互に組み合わせます。プーリング層を追加し、summaryを出力して下さい。※ヒント：output shapeの形からpool_sizeの数を推定しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 「4.3」と同じ要領でコンボリューション層を追加しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "=================================================================\n",
      "Total params: 9,568\n",
      "Trainable params: 9,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 コンボリューション層とプーリング層の出力が3次元であることが分かります。また画像のサイズ（高さ、幅）は層を経るにつれて、縮小していることが分かります。次の手順は3次元の出力をDense層に入力することですが、その前に1次元に変換する必要があります。1次元に変換する「変換層」を追加し、summaryの内容を確認して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3872)              0         \n",
      "=================================================================\n",
      "Total params: 9,568\n",
      "Trainable params: 9,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7 Dense層を追加した後、ソフトマックス関数を用いて、出力層を追加して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3872)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                123936    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 133,834\n",
      "Trainable params: 133,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.8 「3.5」の条件でcompileを設定し、epochsは「4」、batch_sizeは「100」に設定して学習を行って下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "600/600 [==============================] - 20s 33ms/step - loss: 0.8602 - accuracy: 0.7605\n",
      "Epoch 2/4\n",
      "600/600 [==============================] - 23s 39ms/step - loss: 0.3272 - accuracy: 0.9029\n",
      "Epoch 3/4\n",
      "600/600 [==============================] - 26s 44ms/step - loss: 0.2650 - accuracy: 0.9218\n",
      "Epoch 4/4\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.2225 - accuracy: 0.9339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa26d582ed0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=4, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.9 CNNを使用することでかなりの高精度が実現できました。画像データは良い特徴量を内部で作り出せるCNNが適しています。最後に最適化手法の「rmsprop」を「4.8」と同様の条件で学習を行って下さい。※モデルは初期化して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 0.1626 - accuracy: 0.9554\n",
      "Epoch 2/4\n",
      "600/600 [==============================] - 31s 51ms/step - loss: 0.0575 - accuracy: 0.9825\n",
      "Epoch 3/4\n",
      "600/600 [==============================] - 30s 50ms/step - loss: 0.0394 - accuracy: 0.9879\n",
      "Epoch 4/4\n",
      "600/600 [==============================] - 31s 52ms/step - loss: 0.0296 - accuracy: 0.9909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa2715bec10>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=4, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.10 学習データに対して約99%程度正解率があるようです。「4.9」で作成したモデルで（X_test[0]）に対して予測結果を出力してみましょう。※「3.17」と数字を比較して見て下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.8907701e-09, 3.3230671e-07, 1.2059525e-05, 8.5817856e-06,\n",
       "       4.0255402e-10, 6.5422213e-08, 4.3612388e-14, 9.9996972e-01,\n",
       "       8.7307484e-08, 9.2497366e-06], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.11 配列のままだと少し分かりづらいので、結果をグラフ化してみましょう。※ディープラーニングより「7」の値が1に近く、確信度が上がっていることが分かります。（より自信を持って「1」ということができている。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(model.predict(X_test)[0]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.12 「7」と言う予測結果が出ています。「1.9」の方法で実際のデータの結果を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = X_test[0].reshape(28, 28)\n",
    "plt.imshow(b, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.13 コンボリューション層で行っている処理のイメージを掴んでみましょう。下記の様な5×5の乱数行列を作成して下さい。※seedを0で固定して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.14 コンボリューション層は画像データにカーネルをかけ合わせる（行列演算）を行うことで、畳み込まれた特徴を生成します。（特徴マップと言います）下記の様なカーネル（3×3の行列)を作成して下さい。※畳み込み操作を行う為のフィルタのことです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.15 「4.14」で作成したカーネルを「4.13」の疑似画像データにかけ合わせて（行列演算）下記の様な特徴マップを出力して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.16 プーリング層のイメージを掴んでみましょう。4.13と同じ、5×5の乱数行列を作成して下さい。※seedを0で固定して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.17 下記の様な2×2の少領域毎に、最大の値を選択し、4×4の正方行列を作成して下さい。※Pooling層は大抵、Convolutoin層の後に適用されます。役割としては入力データをより扱いやすい形に変形するために、情報を圧縮することが目的です。「max_pooling」と呼ばれる処理になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. RNNについて学習します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0 事前準備　下記コードを読み込んで下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 頻度順位10000語までを指定\n",
    "from keras.datasets import imdb\n",
    "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# 元データのレビュー内容は例えば以下の様なデータが格納されています。\n",
    "def decode_review(num):\n",
    "    word_index = imdb.get_word_index()\n",
    "    reversed_word_index = dict(\n",
    "        [value, key] for (key, value) in word_index.items())\n",
    "\n",
    "    decoded_review = ' '.join([reversed_word_index.get(i-3, '?') for i in X_train[num]])\n",
    "    \n",
    "    return decoded_review\n",
    "\n",
    "decode_review(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 学習データ、検証データのデータ型を調べてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (25000,)\n",
      "X_test: (25000,)\n",
      "y_train: (25000,)\n",
      "y_test: (25000,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train:', X_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 それぞれ25000行のデータが格納されている様です。学習データ「X_train[0]とX_train[1]」の中身を確認してみましょう。それぞれ「行数（単語数）」、「最大値」、「最小値」、「ユニーク数」を出力して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train[0]行数 218\n",
      "X_train[0]最大値 7486\n",
      "X_train[0]最小値 1\n",
      "X/train[0]ユニーク数 120\n",
      "X_train[1]行数 189\n",
      "X_train[1]最大値 9837\n",
      "X_train[1]最小値 1\n",
      "X_train[1]ユニーク数 121\n"
     ]
    }
   ],
   "source": [
    "print('X_train[0]行数', len(X_train[0]))\n",
    "print('X_train[0]最大値', np.array(X_train[0]).max())\n",
    "print('X_train[0]最小値', np.array(X_train[0]).min())\n",
    "print('X/train[0]ユニーク数', pd.Series(X_train[0]).nunique())\n",
    "\n",
    "print('X_train[1]行数', len(X_train[1]))\n",
    "print('X_train[1]最大値', np.array(X_train[1]).max())\n",
    "print('X_train[1]最小値', np.array(X_train[1]).min())\n",
    "print('X_train[1]ユニーク数', pd.Series(X_train[1]).nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 同様に学習データ（y_train）の中身を確認してみましょう。「行数」、「最大値」、「最小値」、「ユニーク数」を出力して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行数 25000\n",
      "最大値 1\n",
      "最小値 0\n",
      "ユニーク数 2\n"
     ]
    }
   ],
   "source": [
    "print('行数', len(y_train))\n",
    "print('最大値', np.array(y_train).max())\n",
    "print('最小値', np.array(y_train).min())\n",
    "print('ユニーク数', pd.Series(y_train).nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 今回のデータは各レビューに対し、「0」か「1」の教師データが対応しているようです。そして、各レビュー内の単語に対し出現頻度の順位が数値として、各単語に割り当てられています。学習データの「行数」が異なるので揃えていきましょう。今回は「500」で設定して下さい。※ヒント：preprocessingのモジュールのsequenceを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (25000, 500)\n",
      "X_test (25000, 500)\n",
      "X_train[0] [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    1   14   22   16   43  530  973 1622 1385   65  458 4468\n",
      "   66 3941    4  173   36  256    5   25  100   43  838  112   50  670\n",
      "    2    9   35  480  284    5  150    4  172  112  167    2  336  385\n",
      "   39    4  172 4536 1111   17  546   38   13  447    4  192   50   16\n",
      "    6  147 2025   19   14   22    4 1920 4613  469    4   22   71   87\n",
      "   12   16   43  530   38   76   15   13 1247    4   22   17  515   17\n",
      "   12   16  626   18    2    5   62  386   12    8  316    8  106    5\n",
      "    4 2223 5244   16  480   66 3785   33    4  130   12   16   38  619\n",
      "    5   25  124   51   36  135   48   25 1415   33    6   22   12  215\n",
      "   28   77   52    5   14  407   16   82    2    8    4  107  117 5952\n",
      "   15  256    4    2    7 3766    5  723   36   71   43  530  476   26\n",
      "  400  317   46    7    4    2 1029   13  104   88    4  381   15  297\n",
      "   98   32 2071   56   26  141    6  194 7486   18    4  226   22   21\n",
      "  134  476   26  480    5  144   30 5535   18   51   36   28  224   92\n",
      "   25  104    4  226   65   16   38 1334   88   12   16  283    5   16\n",
      " 4472  113  103   32   15   16 5345   19  178   32]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "print('X_train', X_train.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('X_train[0]', X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 説明変数のサイズが揃い、準備は整いました。現在扱っている「テキストデータ」や「時系列データ等」、データの「順序」に意味があるデータに関しては、一般的なディープラーニングやCNNより、RNNのほうが適しています。それでは、RNNを実装してみましょう。layersクラスから「Embedding」、「SimpleRNN」を読み込んで下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.layers.embeddings.Embedding'>\n",
      "<class 'tensorflow.python.keras.layers.recurrent.SimpleRNN'>\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, SimpleRNN\n",
    "print(Embedding)\n",
    "print(SimpleRNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6 Sequentialのクラスを読み込み、modelという変数に格納して下さい。※モデルが初期化されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fa28cc412d0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.7 Embedding層を追加して下さい。Embeddingとは単語や文を固定のベクトルに置き換える処理のことです。出力数は「10」を設定しましょう。※Embeddingは本来は特徴量エンジニアリングに分類されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 10)          100000    \n",
      "=================================================================\n",
      "Total params: 100,000\n",
      "Trainable params: 100,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Embedding(10000, 10))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.8 RNN層を追加して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 10)          100000    \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 30)                1230      \n",
      "=================================================================\n",
      "Total params: 101,230\n",
      "Trainable params: 101,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(SimpleRNN(30))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.9 出力層を追加しましょう。活性化関数はシグモイドを設定して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 10)          100000    \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 30)                1230      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 101,261\n",
      "Trainable params: 101,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.10 compileの設定をしましょう。最適化関数を「rmsprop」を選択して下さい。誤差関数を「binary_crossentoropy」で設定し、metricsは「正解率」を設定してみましょう。※何を目的として重みを更新指定行くかを決定している部分になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.11 エポック数は「4」、バッチサイズは「100」、validation_splitを「0.2」に設定して学習を開始して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.2493 - acc: 0.9048 - val_loss: 0.3314 - val_acc: 0.8740\n",
      "Epoch 2/4\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.2131 - acc: 0.9188 - val_loss: 0.3318 - val_acc: 0.8610\n",
      "Epoch 3/4\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.1940 - acc: 0.9283 - val_loss: 0.4299 - val_acc: 0.8430\n",
      "Epoch 4/4\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.1794 - acc: 0.9345 - val_loss: 0.3879 - val_acc: 0.8324\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(X_train, y_train, epochs=4, batch_size=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.12 「学習データ(acc)」、「検証データ(val_acc)」の精度をエポック毎にグラフを表示して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = train.history['acc']\n",
    "val_acc = train.history['val_acc']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'bo', label='acc')\n",
    "plt.plot(epochs, val_acc, 'go', label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.13 学習データ・検証データに対して約80％以上の正解率があるようです。「5.12」で作成したモデルで（X_train[1]）に対して予測結果を出力してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9683858], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.14 悪いレビューである可能性が高そうです。事前準備「5.0」を利用してレビュー内容を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal ? the hair is big lots of boobs ? men wear those cut ? shirts that show off their ? sickening that men actually wore them and the music is just ? trash that plays over and over again in almost every scene there is trashy music boobs and ? taking away bodies and the gym still doesn't close for ? all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.15 実際の正解データを確認していきましょう。y_train[1]のラベルを確認して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train[1]: 0\n"
     ]
    }
   ],
   "source": [
    "print('y_train[1]:', y_train[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
