{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネット実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. データの特徴について確認します。（13問）\n",
    "    - 各変数のデータ型、行列数、統計量を算出し、今回扱うデータの外観を把握します。\n",
    "2. データを加工する方法について学習します。（7問）\n",
    "    - 各変数をモデルに入れる形に整えます。（特徴量生成フェーズ）\n",
    "3. ニューラルネットワークのモデリング方法について学習します。（19問）\n",
    "    - ディープラーニングのモデリングと精度を上げるときのポイントについて学習します。\n",
    "4. CNNについて学習します。（17問）\n",
    "    - 画像データに対して相性の良いCNNモデルについて学習します。\n",
    "5. RNNについて学習します。（15問）\n",
    "    - 時系列、テキストデータ等に対して相性の良いRNNモデルについて学習します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 事前準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1  必要なライブラリを読み込んで下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# 目的変数の加工処理で必要なライブラリ\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# Jupyter 上で図を表示するためのコマンド\n",
    "%matplotlib inline\n",
    "\n",
    "# warningを表示させない\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2 minstを読み込んで、学習データ（説明変数）、学習データ（目的変数）、検証データ（説明変数）、検証データ（目的変数）にデータを格納してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.データの特徴について確認します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1説明変数の学習データ（X_train）の レコード数を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 目的変数の学習データ（y_train）レコード数を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3（X_train）の行列数（各次元の要素数）を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 今回の学習データは3次元の性質を持っているようです。今度は正解データの性質を確認してみましょう。（y_train）の行列数を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 正解データは1次元です。X_trainの1番目（indexは0）のデータの中身を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 同様にy_trainのデータの中身を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 y_trainの要素の集計を行いましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5923\n",
       "1    6742\n",
       "2    5958\n",
       "3    6131\n",
       "4    5842\n",
       "5    5421\n",
       "6    5918\n",
       "7    6265\n",
       "8    5851\n",
       "9    5949\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8 目的変数は0～9までの数字が割り当てられているようです。説明変数と目的変数それぞれの学習データ、検証データの次元数を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.9 学習データは60000件、検証データは10000件、学習データの要素数は28×28、それに対して0～9の正解データが存在していることが分かりました。最初の学習データ（indexは0）を可視化してみましょう。※ヒント：「plt.imshow」を使用してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = X_train[0]\n",
    "plt.imshow(a, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.10 色の濃さはどのように表現されているのでしょうか。最初の学習データ（0番目）の最初の要素（0番目）を出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.11 最初の学習データ（indexは0）の6番目の要素（indexは5）を出力してください。※画像と数字を比較して見てください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "        18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "         0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.12 最初の学習データ（indexは0）を転置させて、6番目の要素（indexは5）を出力してください。※画像と数字を比較して見てください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 172, 253,   0,\n",
       "         0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].T[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.13 学習データの構成は（60000,28,28）＝（枚数,横座標,縦座標）を表しており、数字が小さいと「白」、大きいと「黒」を表現しているようです。最後にtrain_xの最大値、最小値を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.max())\n",
    "print(X_train.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.データの加工方法について学習します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 kerasに入れる形にデータを整えていきましょう。まず、28×28の画像データ（X_train,X_test）を全て（60000枚）1次元化してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 784)\n",
      "X_test: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 ディープラーニングは正規化処理を施した方が適切な結果が出ることが多いです。28×28の画像データ（X_train,X_test）の最大値が1になるように正規化してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_max: 1.0\n",
      "X_test_min: 0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "print(\"X_train_max:\",X_train.max())\n",
    "print(\"X_test_min:\",X_test.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 目的変数の形を「0」、「1」だけで表す必要があります。整数値を2値クラスの配列に変換した上で、y_trainを上から5行表示してください。※ワンホットエンコーディング処理といいます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "t_test = to_categorical(y_test, 10)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 説明変数と目的変数の形式は整いました。それでは各ノードにおける「入力」と「出力」のイメージを理解していきましょう。下記の様な「2×3」の行列を作成して、「w」と言う変数に格納して下さい。同様に「3×1」の行列を作成し、「x」という変数に格納して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 「3個のデータ」である「x」に重み「w」をかけ合わせて「2個のデータ」を出力してみましょう。※行列演算を行います。ニューラルネットワークはデータに重みをかけ合わせて新たな数値を出力し、その数値を活性化関数で変換して出てきた値を次の層の入力とすることの繰り返しです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 活性化関数のイメージを掴んでいきましょう。「2.5」で算出した行列に、活性化関数の一種である「シグモイド関数」をかけて値を算出して下さい。※値が0～1の間に収まる関数です。kerasでは引数で設定することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7 活性化関数のイメージを掴んでいきましょう。「2.5」で算出した行列に、活性化関数の一種である「relu」をかけて値を算出して下さい。※正の値はそのまま、負の値は「0」に変換する関数です。kerasでは引数で設定することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.ニューラルネットワークのモデリング方法について学習します。※layerの名前、精度結果が一致している必要は無いです。また、モデリングの実行後、時間がかかる処理があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Sequentialのクラスを読み込み、modelという変数に格納して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.engine.sequential.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "print(Sequential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 全結合レイヤーである「Dense」のクラスを読み込んで下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.layers.core.Dense'>\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "print(Dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 今回は「Sequentialモデル」を使用して、ニューラルネットワークを構築していきましょう。「784」件の入力を受け取り、「32」件の出力を返し、活性化関数が「シグモイド関数」の層を作成してください。※32件にしている理由は特にありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                25120     \n",
      "=================================================================\n",
      "Total params: 25,120\n",
      "Trainable params: 25,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='sigmoid', input_dim=784))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 「10」件の出力を返す、活性化関数がソフトマックス関数の出力層を追加し、サマリーを出力して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 学習方法をcompile関数で設定しましょう。最適化関数を「確率的勾配降下法（Stochastic gradient descent）」を選択して下さい。誤差関数を「categorical_crossentoropy」で設定し、metricsは「正解率」を設定してみましょう。※何を目的として重みを更新するかを決定している部分になります。※確率的勾配降下法は難しい概念なので、本コンテンツでは説明しません。詳しく知りたい方は調べてみて下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 学習を実行しましょう。fit関数に学習データを当てはめて下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 550us/step - loss: 1.6701 - accuracy: 0.63420s - los\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 「3.6」の学習を、epochs「4」で設定して行って下さい。※epochsとは「一つの訓練データを何回繰り返して学習させるか」の数のことです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1875/1875 [==============================] - 1s 502us/step - loss: 0.9053 - accuracy: 0.8229\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 1s 551us/step - loss: 0.6436 - accuracy: 0.8610\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 1s 532us/step - loss: 0.5263 - accuracy: 0.8781\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 1s 595us/step - loss: 0.4595 - accuracy: 0.8880\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(X_train, y_train, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8 学習を繰り返せば、精度が向上することが確認できます。「3.7」の学習を、batch_size=「100」で設定して行って下さい。※batchとは、訓練データをいくつかのかたまりに分割したものを指します。batch_sizeとはそのかたまりのサイズを指します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.4282 - accuracy: 0.8934\n",
      "Epoch 2/4\n",
      "600/600 [==============================] - 1s 968us/step - loss: 0.4163 - accuracy: 0.8947\n",
      "Epoch 3/4\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.4056 - accuracy: 0.8961\n",
      "Epoch 4/4\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.3962 - accuracy: 0.8978\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(X_train, y_train, epochs=4, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9 学習速度が早くなっていることが確認できます。ディープラーニングは学習時間が非常にかかるので、データによっては速度を意識する必要があることを覚えておきましょう。学習データに対する結果を確認し、x軸に「epoch」、y軸に「accuracy」のグラフを作成して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.10 今度は検証データに対する評価結果を確認してみましょう。誤差と正解率を算出して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1224 test_function  *\n        return step_function(self, iterator)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1215 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1208 run_step  **\n        outputs = model.test_step(data)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1177 test_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-794c524bc0ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1224 test_function  *\n        return step_function(self, iterator)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1215 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1208 run_step  **\n        outputs = model.test_step(data)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1177 test_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /Users/yutokunakasa/opt/anaconda3/envs/py37env/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy  = model.evaluate(X_test, y_test, verbose=False)\n",
    "print('loss:',loss)\n",
    "print('accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エラーが出たため、解答を確認しても同じエラーが出てしまう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.11 「3.8」の条件と、中間層を「1つ」追加した時と「2つ」追加した時の「モデルサマリ」、「正解率推移」、「評価指標」を確認して下さい。※今までの処理を関数化するイメージです。中間層の入力数と出力数は「32」で設定しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.12 層を増やせば増やすほど、学習データの精度が劣化していることが確認できました。次は「3.11」の「中間層を2層追加した状態」でエポック数を40回に設定し、学習データの精度の推移を確認して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.13 「3.12」の条件に加えてepochsを「10」で設定し、学習データと検証データの「誤差」の推移を確認してグラフを出力して下さい。※モデルを初期化する必要はないです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.14「学習データ」、「検証データ」共に、誤差が減少していることが分かります。複雑なモデルには、沢山の学習が必要なようです。今度は中間層無しで入力数を[32, 64, 128, 256]と変更したときの。学習データの精度を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.15 入力数を増やした結果、層を増やした結果より効果が得られました。モデルは複雑になり過ぎず、簡単になり過ぎず、様々な条件を試行して、良いバランスを目指す必要があります。活性化関数を「relu」に変更し、その他は「3.11」の条件で精度を確認してみて下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.16 活性化関数は「sigmoid」ではなく「relu」を使用した方が、一般的には良い精度が得られることが多いです。compileの最適化関数も変更してみましょう。「sgd」から「rmsprop」に変更して精度を確認して下さい。※データによって「最適なモデル」の条件は異なります。様々な観点で試行していくことが重要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.17 約90%程度正解率があるようです。「3.16」で作成したモデルで（X_test[0]）に対して予測結果を出力してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.18 配列のままだと少し分かりづらいので、結果をグラフ化してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.19 「7」と言う予測結果が出ています。「1.9」の方法で実際のデータの結果を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.CNNについて学習します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Sequentialのクラスを読み込み、modelという変数に格納して下さい。※先程作成したモデルが初期化されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fe1d902a950>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 CNNの入力は画像の形式のまま扱う必要があります。X_trainとX_testの形状を画像の形式に変更して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28, 1)\n",
      "X_test: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "print('X_train:',X_train.shape)\n",
    "print('X_test:',X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 CNNを構築していきましょう。先ずは活性化関数を「relu」に設定してコンボリューション層を追加し、summaryを出力して下さい。※ヒント：output shapeの形からストライド（移動する幅）の数を推定しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Conv2D(32, (3,3),activation='relu',input_shape=(28, 28, 1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 CNNはコンボリューション層とプーリング層を交互に組み合わせます。プーリング層を追加し、summaryを出力して下さい。※ヒント：output shapeの形からpool_sizeの数を推定しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 「4.3」と同じ要領でコンボリューション層を追加しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "=================================================================\n",
      "Total params: 9,568\n",
      "Trainable params: 9,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 コンボリューション層とプーリング層の出力が3次元であることが分かります。また画像のサイズ（高さ、幅）は層を経るにつれて、縮小していることが分かります。次の手順は3次元の出力をDense層に入力することですが、その前に1次元に変換する必要があります。1次元に変換する「変換層」を追加し、summaryの内容を確認して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3872)              0         \n",
      "=================================================================\n",
      "Total params: 9,568\n",
      "Trainable params: 9,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7 Dense層を追加した後、ソフトマックス関数を用いて、出力層を追加して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3872)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                123936    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 133,834\n",
      "Trainable params: 133,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.8 「3.5」の条件でcompileを設定し、epochsは「4」、batch_sizeは「100」に設定して学習を行って下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.8086 - accuracy: 0.7676\n",
      "Epoch 2/4\n",
      "600/600 [==============================] - 20s 33ms/step - loss: 0.3036 - accuracy: 0.9083\n",
      "Epoch 3/4\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.2486 - accuracy: 0.9258\n",
      "Epoch 4/4\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.2100 - accuracy: 0.9374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe1d93f3b50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=4, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.9 CNNを使用することでかなりの高精度が実現できました。画像データは良い特徴量を内部で作り出せるCNNが適しています。最後に最適化手法の「rmsprop」を「4.8」と同様の条件で学習を行って下さい。※モデルは初期化して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "600/600 [==============================] - 19s 32ms/step - loss: 0.1626 - accuracy: 0.9549\n",
      "Epoch 2/4\n",
      "600/600 [==============================] - 23s 39ms/step - loss: 0.0577 - accuracy: 0.9819\n",
      "Epoch 3/4\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0390 - accuracy: 0.9880\n",
      "Epoch 4/4\n",
      "600/600 [==============================] - 26s 44ms/step - loss: 0.0301 - accuracy: 0.9909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe1bc2579d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=4, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.10 学習データに対して約99%程度正解率があるようです。「4.9」で作成したモデルで（X_test[0]）に対して予測結果を出力してみましょう。※「3.17」と数字を比較して見て下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.1354513e-11, 6.1864434e-08, 6.6675248e-08, 1.3518003e-07,\n",
       "       1.1067863e-12, 1.4179240e-10, 5.3324155e-16, 9.9999964e-01,\n",
       "       9.0643777e-09, 3.7008572e-08], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.11 配列のままだと少し分かりづらいので、結果をグラフ化してみましょう。※ディープラーニングより「7」の値が1に近く、確信度が上がっていることが分かります。（より自信を持って「1」ということができている。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbaUlEQVR4nO3da2xk93nf8e8zwzt5dle7JIfW7kpcWZxp1kYCGwvXrYHWqF1DclvpRS+wAPcSGFFfxInTuC2ctFADt2/SFOkFVdMqaRo0Te2qrtEukm1VoHHRoqgNre3EiaTOkF6vtLsyh9z74f0yT1/MHIo7Sy6H5BmemXN+H0AAZ+Zo5tHY+9vD5zzn/zd3R0REul8u6QJERCQeCnQRkZRQoIuIpIQCXUQkJRToIiIp0ZPUB4+Ojvrk5GRSHy8i0pW+/e1v33T3sZ1eSyzQJycnuXz5clIfLyLSlczs7d1eU8tFRCQlFOgiIimhQBcRSQkFuohISijQRURSYs9AN7NfN7M5M/vDXV43M/tnZjZjZt8zsw/HX6aIiOyllTP03wCeecTrzwJTjX9eBH7l8GWJiMh+7Rno7v6/gNuPOOR54N963TeBE2b2vrgKFJHu9r3rd/nOO3eSLiMT4uihnwaubXt8vfHcQ8zsRTO7bGaX5+fnY/hoEel0L/2XN/j5r/9B0mVkwpFeFHX3V9z9grtfGBvb8c5VEUmRWs2pVEO+P7/A+mYt6XJSL45AvwGc3fb4TOM5Ecm4G3eXWVrbZH3TuXpzMelyUi+OQL8I/JXGtMtHgXvu/sMY3ldEulx5Nnzv52r4iCMlDnsuzmVmXwE+Doya2XXg7wG9AO7+L4FLwKeBGWAJ+PF2FSsi3SUK8ZxBZTaEH024oJTbM9Dd/YU9XnfgJ2OrSERSY7oacvrEIP29OSrVhaTLSb3Els8VkfQrVxcoFkYY6M0/0H6R9tCt/yLSFhubNb4/t0CxEDBVCLh6a5GV9c2ky0o1BbqItMXVW0usbdYoFgJKhYCaw8yc2i7tpEAXkbaoNC6IliYCShMjDzwn7aEeuoi0RaUaYgZPj4+Qzxl9eV0YbTcFuoi0RaUaMnlqmIHePABPjQ3rDL3N1HIRkbYoz4ZMjY9sPS4WAk26tJkCXURit7K+ydVbS5Qmgq3nShMBN+4uE66sJ1hZuinQRSR2V+YX2aw5xcJ7gR79PK1Jl7ZRoItI7Kbn3ptwiZSiQFcfvW0U6CISu/JsSG/emDw1vPXcmccGGezNU57VGXq7KNBFJHaVasi50WH6et6LmFzOmCqMaNKljRToIhK7cjV8oH8eKRYCLaPbRgp0EYnV0toG124vb/XMtysVAubDVe4sriVQWfop0EUkVtONu0GLEzucoTeeU9ulPRToIhKrqKWy2xk6KNDbRYEuIrGqzIb09+Q4e3LoodcKx/oJBnrUR28TBbqIxKpcDZkq1BfkamZmlAoBFY0utoUCXURiNV1d2HHCJVKcqE+61HevlDgp0EUkNveW1pm9v7Jj/zxSKgTcW15nPlw9wsqyQYEuIrGpNG7532nCJRKdvauPHj8FuojEJloe95Etl8LIA8dKfBToIhKbSjVkpL+Hx48P7HrMqZF+Rkf6NLrYBgp0EYlNpRpSLIxg9vCEy3b1JQA06RI3BbqIxMLdKc+GDyyZu5tiIWCmGlKradIlTgp0EYnFzYU17iytP7J/HilNBCyubXLj7vIRVJYdCnQRiUXUE28l0KMLo+qjx0uBLiKxaGXCJTKl0cW2UKCLSCym50JODvcxOtK357HHBnp5/PgAFY0uxkqBLiKxKM+2NuESKU4EVDTpEisFuogcmrtT2WMNl2bFQsDM/AIbm7U2VpYtLQW6mT1jZmUzmzGzL+3w+hNm9g0z+66Zfc/MPh1/qSLSqd69t8LC6sa+A31to8bbt5faWFm27BnoZpYHXgaeBc4DL5jZ+abD/i7wqrt/CPgM8C/iLlREOlfUC29lBj2ytdmF+uixaeUM/SPAjLtfcfc14KvA803HOHCs8fNx4N34ShSRTrc1sjjeeqA/PT6CmSZd4tRKoJ8Grm17fL3x3Ha/AHzWzK4Dl4Cf2umNzOxFM7tsZpfn5+cPUK6IdKJyNWTi2ADHh3pb/ncG+/I8eXJoaw9SOby4Loq+APyGu58BPg38ppk99N7u/oq7X3D3C2NjYzF9tIgkrdLYpWi/pgqBztBj1Eqg3wDObnt8pvHcdp8DXgVw9/8LDACjcRQoIp1ts+ZMVxceuanFbkqFgB/cXGR1Y7MNlWVPK4H+OjBlZufMrI/6Rc+LTce8A3wCwMx+hHqgq6cikgHv3F5idaP2yE0tdlOcCNisOVfmF9tQWfbsGejuvgF8HngNeIv6NMsbZvZlM3uucdgXgZ8ws98HvgL8NdeGgSKZEF0QPegZ+vb3kMPpaeUgd79E/WLn9ude2vbzm8DH4i1NRLpBNHZ4kB76udFhenKmQI+J7hQVkUMpV0POnhxkqK+l88MH9PXkODc6THlWky5xUKCLyKFUquGB2i2R+pouOkOPgwJdRA5sbaPGlfnFfd3y36xUCHjn9hJLaxsxVpZNCnQRObCrtxbZqPm+bvlvFv1loBuMDk+BLiIHtp9NLXYT/WWgtsvhKdBF5MAq1ZB8znhqbPjA7/HEySH6e3IK9Bgo0EXkwMqzIZOnhujvyR/4PfI54+nxEcpquRyaAl1EDqxSDQ/VP4+UCoGW0Y2BAl1EDmRlfZO3by8dqn8eKU4EzN5f4d7yegyVZZcCXUQOZGZuAfeD3fLfrLQ16aKz9MNQoIvIgZS3bvk/fKBHywZoKd3DUaCLyIFUqiF9+RyTp4YO/V6nTwwy3JdXH/2QFOgiciDlasj7x0foyR8+RsyM4oQ2uzgsBbqIHEh9U4v9r7C4m1IhoKLRxUNRoIvIvoUr69y4u3ygTS12UywE3F5c4+bCamzvmTUKdBHZt+hMujgeb6AD6qMfggJdRPZta5eiOM/QJzTpclgKdBHZt/JsyFBfntMnBmN7z7GRfh4b6tWaLoegQBeRfZueC5kqBORyFtt7mhnFQrA13y77p0AXkX0rz8Y74RIpTQRMVxfQHvMHo0AXkX25tbDKzYXVWNZwaTZVCAhXN/jhvZXY3zsLFOgisi9bEy5tCPRoTRddGD0YBbqI7Mv0XPwTLpFio42j0cWDUaCLyL6UZ0OOD/YyHvTH/t4nhvooHOvXGfoBKdBFZF8q1ZBSIcAsvgmX7YqFQBtGH5ACXURa5u6UZ8Ot5W7boVgImJ4L2axp0mW/FOgi0rLq/VXur2y0pX8eKRUCVtZrXLu91LbPSCsFuoi0LLqLsx0TLpFowS/10fdPgS4iLTuKQJ8a16TLQSnQRaRl5dmQsaCfk8N9bfuM4f4ezp4cpDKnC6P71VKgm9kzZlY2sxkz+9Iux/wlM3vTzN4ws38fb5ki0gkq1XBrVrydiuOBztAPYM9AN7M88DLwLHAeeMHMzjcdMwX8HPAxd/8A8DPxlyoiSarVnEp1oa3tlkhxIuD78wusbdTa/llp0soZ+keAGXe/4u5rwFeB55uO+QngZXe/A+Duc/GWKSJJu3F3meX1za3b89upVAjYqDlXby22/bPSpJVAPw1c2/b4euO57YpA0cz+j5l908ye2emNzOxFM7tsZpfn5+cPVrGIJCJa1jbObed2E/0WoKV09yeui6I9wBTwceAF4FfN7ETzQe7+irtfcPcLY2NjMX20iByFaIwwmkJpp6fGhsnnjGmNLu5LK4F+Azi77fGZxnPbXQcuuvu6u/8AqFAPeBFJiUo15PSJQYKB3rZ/1kBvnidPDWkWfZ9aCfTXgSkzO2dmfcBngItNx/xn6mfnmNko9RbMlfjKFJGklWePZsIlUioEW0v1Smv2DHR33wA+D7wGvAW86u5vmNmXzey5xmGvAbfM7E3gG8Dfcvdb7SpaRI7WxmaNK/OLR9I/jxQLAVdvLbKyvnlkn9ntelo5yN0vAZeanntp288O/GzjHxFJmau3lljbrB3JhEukNBHgDjNzC3zw9PEj+9xupjtFRWRPR3HLf7OtzS7UR2+ZAl1E9lSeDTGDp49gwiXy5Klh+vI5XRjdBwW6iOypUg2ZPDXMQG/+yD6zN5/jqbFhLQGwDwp0EdnTUa3h0qw0oUmX/VCgi8gjraxvcvXW0pFeEI0UCwE37i4Trqwf+Wd3IwW6iDzSlflFNmvOVEKBDjCtpXRbokAXkUeKpkzaue3cbqLfCtRHb40CXUQeqVwN6c0bk6eGj/yzzzw2yGBvXpMuLVKgi8gjTVdDnhodoa/n6OMilzOKhRHNordIgS4ij1Suhkd6y3+zYiGgPKseeisU6CKyq8XVDa7dXqZ4hDcUNSsWAm4urHJ7cS2xGrqFAl1EdhVNlyR6ht74bLVd9qZAF5FdRdMlScygR7YmXRToe1Kgi8iuKtWQgd4cZ08OJVZD4Vg/xwZ6tB1dCxToIrKrcjVkajwgn7PEajCzxhIACvS9KNBFZFeVashUAmu4NJtq7F5U33pBdqNAF5Ed3V1ao3p/NdH+eaRUCLi3vM5cuJp0KR1NgS4iO4pWOUxywiUSremiPvqjKdBFZEdba7h0wBm6di9qjQJdRHZUqYYE/T287/hA0qVwaqSf0ZF+naHvQYEuIjsqz9YviJolN+GyXbEwQkXL6D6SAl1EHuLuVKphIkvm7qZYCJiuhtRqmnTZjQJdRB4yv7DKnaX1rYuRnaA0EbC0tsmNu8tJl9KxFOgi8pDpxoRLJ1wQjWjSZW8KdBF5SBSanTCyGIkmXbTZxe4U6CLykEo15ORwH6Mj/UmXsiUY6OXx4wNMK9B3pUAXkYeUq+HWGXEnKU4ElKuadNmNAl1EHuDuTFcXOqp/HikVAr4/t8DGZi3pUjqSAl1EHvDuvRUWVjc6qn8eKRYC1jZrXL21lHQpHUmBLiIP6IRNLXZT0u5Fj6RAF5EHRFMkUx0Y6O8fG8FMgb6blgLdzJ4xs7KZzZjZlx5x3J83MzezC/GVKCJHqTIbMnFsgOODvUmX8pDBvjxPnhxSoO9iz0A3szzwMvAscB54wczO73BcAHwB+FbcRYrI0anMhR3ZP48UC4FuLtpFK2foHwFm3P2Ku68BXwWe3+G4vw/8IrASY30icoQ2a9GES+eNLEZKEwFXby2xsr6ZdCkdp5VAPw1c2/b4euO5LWb2YeCsu//Oo97IzF40s8tmdnl+fn7fxYpIe71ze4nVjVpHreHSrFgI2Kw5V+YXky6l4xz6oqiZ5YBfBr6417Hu/oq7X3D3C2NjY4f9aBGJ2dYt/x0e6ADTc2q7NGsl0G8AZ7c9PtN4LhIAHwT+p5ldBT4KXNSFUZHuU9macOnclsu50WF6cqY++g5aCfTXgSkzO2dmfcBngIvRi+5+z91H3X3S3SeBbwLPufvltlQsIm1TqYY8cXKIob6epEvZVV9PjqfGhjXpsoM9A93dN4DPA68BbwGvuvsbZvZlM3uu3QWKyNGpVMOObrdEioVAqy7uoKW/ht39EnCp6bmXdjn244cvS0SO2tpGjSvzi/zp84WkS9lTqRDw29/7IYurGwz3d+5vE0dNd4qKCAA/uLnIRs274gw9uot1RnuMPkCBLiLAe7f8d0OgR2u6qO3yIAW6iAAwXQ3J54ynxoaTLmVPT5wcor8nt7WQmNQp0EUEqM+gnxsdpr8nn3Qpe8rnjKnCiM7QmyjQRQSIJlw6d/68WXE80OhiEwW6iLC8tsnbt5e6on8eKU4EVO+vcm9pPelSOoYCXUSYmVvAvTM3tdhNVGtFSwBsUaCLyFbropOXzW0W1aolAN6jQBcRKtWQvp4cT54cSrqUlj1+fICR/h710bdRoIsI5WrI+8dG6Ml3TySYNSZddIa+pXv+1xORtqnMhh29qcVuSoX6pIu7J11KR1Cgi2Tc/ZV13r230lX980ixEHBnaZ2bC2tJl9IRFOgiGTddra+H0k0TLpFoCQD10esU6CIZV+miNVyaRTWrj16nQBfJuPJsyFBfntMnBpMuZd9GR/p4bKhXZ+gNCnSRjKtUQ6YKAbmcJV3KvpkZxYKWAIgo0EUyrlLtzgmXSGkioFJd0KQLCnSRTLu1sMrNhbWu7J9HioWAhdUN3r23knQpiVOgi2RYJZpw6cKRxcjWpIsujCrQRbKsmydcIsVx7V4UUaCLZFi5GnJ8sJfxoD/pUg7s+FAvhWP9ujCKAl0k0+q3/AeYdd+Ey3aadKlToItklLvXdyma6N4Jl0ipEDBdXWCzlu1JFwW6SEZV769yf2WjK2/5b1acCFjdqPHO7aWkS0mUAl0ko6KLiFNpCHQtAQAo0EUyKxrz6+YJl8jUeL1tlPU+ugJdJKPK1ZCxoJ+Tw31Jl3Jow/09nD05qEBPugARScZ0NUxF/zxS0qSLAl0ki2o1p1JdSEW7JVIsBFyZX2Rto5Z0KYlRoItk0PU7yyyvb1Ls4kW5mhULARs15wc3F5MuJTEtBbqZPWNmZTObMbMv7fD6z5rZm2b2PTP7H2b2ZPylikhcogmXbtx2bjdbky4ZbrvsGehmlgdeBp4FzgMvmNn5psO+C1xw9x8Fvgb8w7gLFZH4RL3maDokDZ4aGyafM6YV6I/0EWDG3a+4+xrwVeD57Qe4+zfcPZro/yZwJt4yRSROlWrI6RODBAO9SZcSm4HePJOnhjI9i95KoJ8Grm17fL3x3G4+B/zXnV4wsxfN7LKZXZ6fn2+9ShGJVXk27Oolc3dT3+xCgR4LM/sscAH4pZ1ed/dX3P2Cu18YGxuL86NFpEXrmzWuzC8ylaILopGp8YC3by+xvLaZdCmJaCXQbwBntz0+03juAWb2SeDvAM+5+2o85YlI3N6+tcjaZi1VM+iR0kSAO8zMLSRdSiJaCfTXgSkzO2dmfcBngIvbDzCzDwH/inqYz8VfpojEJdqlKE0z6JHovymrbZc9A93dN4DPA68BbwGvuvsbZvZlM3uucdgvASPAfzSz3zOzi7u8nYgkrDwbkjN4OkUTLpHJU0P05XOZDfSeVg5y90vApabnXtr28ydjrktE2qRSDZk8NcxAbz7pUmLXk8/x/vGRzM6i605RkYwpV8NUXhCNFAsjmd0wWoEukiEr65tcvbmYyguikWIh4N17K9xfWU+6lCOnQBfJkCvzi9Q8Xbf8N4v+spquZm/SRYEukiHRxcI0n6FHN0xl8cKoAl0kQ8rVkN68MTk6nHQpbXP6xCBDfflMLgGgQBfJkMpsyFOjI/Tm0/tHP5czpsZHdIYuIulWroap7p9HihndvUiBLpIRi6sbXL+zTCnFI4uR0kTAzYU1bi1kaxUSBbpIRkzPpfeW/2bvLQGQrUkXBbpIRkQ326Rx2dxmWZ10UaCLZES5GjLQm+PsY0NJl9J240E/xwZ6MrcEgAJdJCMq1ZCp8YBczpIupe3MrL7ZRcZGFxXoIhlRqYaZ6J9HokkXd0+6lCOjQBfJgLtLa1Tvr1KaSP+ES6Q0EXB/ZYPq/exMuijQRTIgmvaYytAZ+tR4/b81S310BbpIBpQzsIZLs2Jj3j5LfXQFukgGVGZDgv4e3nd8IOlSjsypkX5GR/p1hi4i6VJp3PJvlv4Jl+1KEyNMK9BFJC3cPXMTLpH6pMsCtVo2Jl0U6CIpN7+wyp2l9a2ecpYUCwHL65tcv7OcdClHQoEuknKV2fqES5YuiEai30qy0kdXoIukXBRmWVg2t9nWpIsCXUTSYLoacmq4j9GR/qRLOXLBQC+nTwwq0EUkHcoZvSAaKRZGMrMdnQJdJMXcncpsmMkLopFiIeDK/CLrm7WkS2k7BbpIit24u8zi2mYm++eRYiFgbbPG27cWky6l7RToIilWyeAt/82izS7Ks+nfvUiBLpJiWVyUq9nT4yOYZWPSRYEukmKV2ZD3HR/g+GBv0qUkZqA3z+SpYQW6iHS3cjXM9Nl5ZGp8JBM3FynQRVJqs+ZMzy1QyvCES6Q0EXD15iIr65tJl9JWLQW6mT1jZmUzmzGzL+3wer+Z/YfG698ys8nYKxWRfXn71iJrG7VMz6BHioWAmsP359N9YXTPQDezPPAy8CxwHnjBzM43HfY54I67Pw38Y+AX4y5URPYnuiBayvDIYiT6Dqar6Q70nhaO+Qgw4+5XAMzsq8DzwJvbjnke+IXGz18D/rmZmbdhd9ZXX7/Gr/7vK3G/rUjq3F1ex6w+5ZF1k6eG6c0b/+B33uTlb8wkXQ4//Ykp/tyPPR77+7YS6KeBa9seXwf+6G7HuPuGmd0DTgE3tx9kZi8CLwI88cQTByr4xFAvU+oJirTkRyaOMdTXyh/zdOvryfE3P1Xi96/fTboUgLZNHR3p/9Lu/grwCsCFCxcOdPb+qQ9M8KkPTMRal4ik31//k+9PuoS2a+Wi6A3g7LbHZxrP7XiMmfUAx4FbcRQoIiKtaSXQXwemzOycmfUBnwEuNh1zEfirjZ//AvC77eifi4jI7vZsuTR64p8HXgPywK+7+xtm9mXgsrtfBP418JtmNgPcph76IiJyhFrqobv7JeBS03Mvbft5BfiL8ZYmIiL7oTtFRURSQoEuIpISCnQRkZRQoIuIpIQlNV1oZvPA2wf810dpugs14/R9PEjfx3v0XTwoDd/Hk+4+ttMLiQX6YZjZZXe/kHQdnULfx4P0fbxH38WD0v59qOUiIpISCnQRkZTo1kB/JekCOoy+jwfp+3iPvosHpfr76MoeuoiIPKxbz9BFRKSJAl1EJCW6LtD32rA6K8zsrJl9w8zeNLM3zOwLSdfUCcwsb2bfNbPfTrqWpJnZCTP7mpn9PzN7y8z+WNI1JcXM/kbjz8kfmtlXzGwg6ZraoasCvcUNq7NiA/iiu58HPgr8ZIa/i+2+ALyVdBEd4p8C/83d/wjwY2T0ezGz08BPAxfc/YPUlwFP5RLfXRXobNuw2t3XgGjD6sxx9x+6+3caP4fU/7CeTraqZJnZGeDPAL+WdC1JM7PjwJ+gvlcB7r7m7ncTLSpZPcBgY0e1IeDdhOtpi24L9J02rM50iAGY2STwIeBbCZeStH8C/G2glnAdneAcMA/8m0YL6tfMbDjpopLg7jeAfwS8A/wQuOfu/z3Zqtqj2wJdmpjZCPCfgJ9x9/tJ15MUM/uzwJy7fzvpWjpED/Bh4Ffc/UPAIpDJa05m9hj13+TPAY8Dw2b22WSrao9uC/RWNqzODDPrpR7mv+XuX0+6noR9DHjOzK5Sb8X9KTP7d8mWlKjrwHV3j35r+xr1gM+iTwI/cPd5d18Hvg788YRraotuC/RWNqzOBDMz6v3Rt9z9l5OuJ2nu/nPufsbdJ6n//+J33T2VZ2GtcPdZ4JqZlRpPfQJ4M8GSkvQO8FEzG2r8ufkEKb1A3NKeop1itw2rEy4rKR8D/jLwB2b2e43nfr6x/6sIwE8Bv9U4+bkC/HjC9STC3b9lZl8DvkN9Ouy7pHQJAN36LyKSEt3WchERkV0o0EVEUkKBLiKSEgp0EZGUUKCLiKSEAl1EJCUU6CIiKfH/AV1j+ZUIhRRFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(model.predict(X_test)[0]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.12 「7」と言う予測結果が出ています。「1.9」の方法で実際のデータの結果を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = X_test[0].reshape(28, 28)\n",
    "plt.imshow(b, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.13 コンボリューション層で行っている処理のイメージを掴んでみましょう。下記の様な5×5の乱数行列を作成して下さい。※seedを0で固定して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5488135 , 0.71518937, 0.60276338, 0.54488318, 0.4236548 ],\n",
       "       [0.64589411, 0.43758721, 0.891773  , 0.96366276, 0.38344152],\n",
       "       [0.79172504, 0.52889492, 0.56804456, 0.92559664, 0.07103606],\n",
       "       [0.0871293 , 0.0202184 , 0.83261985, 0.77815675, 0.87001215],\n",
       "       [0.97861834, 0.79915856, 0.46147936, 0.78052918, 0.11827443]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.14 コンボリューション層は画像データにカーネルをかけ合わせる（行列演算）を行うことで、畳み込まれた特徴を生成します。（特徴マップと言います）下記の様なカーネル（3×3の行列)を作成して下さい。※畳み込み操作を行う為のフィルタのことです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.15 「4.14」で作成したカーネルを「4.13」の疑似画像データにかけ合わせて（行列演算）下記の様な特徴マップを出力して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.94893369, 3.60633711, 2.62916156],\n",
       "       [2.98631118, 2.76766968, 3.90344315],\n",
       "       [2.8200857 , 3.86679914, 1.99699116]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.16 プーリング層のイメージを掴んでみましょう。4.13と同じ、5×5の乱数行列を作成して下さい。※seedを0で固定して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.17 下記の様な2×2の少領域毎に、最大の値を選択し、4×4の正方行列を作成して下さい。※Pooling層は大抵、Convolutoin層の後に適用されます。役割としては入力データをより扱いやすい形に変形するために、情報を圧縮することが目的です。「max_pooling」と呼ばれる処理になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71518934, 0.891773  , 0.96366274, 0.96366274],\n",
       "       [0.79172504, 0.891773  , 0.96366274, 0.96366274],\n",
       "       [0.79172504, 0.83261985, 0.92559665, 0.92559665],\n",
       "       [0.9786183 , 0.83261985, 0.83261985, 0.87001216]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. RNNについて学習します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0 事前準備　下記コードを読み込んで下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 頻度順位10000語までを指定\n",
    "from keras.datasets import imdb\n",
    "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# 元データのレビュー内容は例えば以下の様なデータが格納されています。\n",
    "def decode_review(num):\n",
    "    word_index = imdb.get_word_index()\n",
    "    reversed_word_index = dict(\n",
    "        [value, key] for (key, value) in word_index.items())\n",
    "\n",
    "    decoded_review = ' '.join([reversed_word_index.get(i-3, '?') for i in X_train[num]])\n",
    "    \n",
    "    return decoded_review\n",
    "\n",
    "decode_review(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 学習データ、検証データのデータ型を調べてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 それぞれ25000行のデータが格納されている様です。学習データ「X_train[0]とX_train[1]」の中身を確認してみましょう。それぞれ「行数（単語数）」、「最大値」、「最小値」、「ユニーク数」を出力して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 同様に学習データ（y_train）の中身を確認してみましょう。「行数」、「最大値」、「最小値」、「ユニーク数」を出力して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 今回のデータは各レビューに対し、「0」か「1」の教師データが対応しているようです。そして、各レビュー内の単語に対し出現頻度の順位が数値として、各単語に割り当てられています。学習データの「行数」が異なるので揃えていきましょう。今回は「500」で設定して下さい。※ヒント：preprocessingのモジュールのsequenceを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 説明変数のサイズが揃い、準備は整いました。現在扱っている「テキストデータ」や「時系列データ等」、データの「順序」に意味があるデータに関しては、一般的なディープラーニングやCNNより、RNNのほうが適しています。それでは、RNNを実装してみましょう。layersクラスから「Embedding」、「SimpleRNN」を読み込んで下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6 Sequentialのクラスを読み込み、modelという変数に格納して下さい。※モデルが初期化されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.7 Embedding層を追加して下さい。Embeddingとは単語や文を固定のベクトルに置き換える処理のことです。出力数は「10」を設定しましょう。※Embeddingは本来は特徴量エンジニアリングに分類されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.8 RNN層を追加して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.9 出力層を追加しましょう。活性化関数はシグモイドを設定して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.10 compileの設定をしましょう。最適化関数を「rmsprop」を選択して下さい。誤差関数を「binary_crossentoropy」で設定し、metricsは「正解率」を設定してみましょう。※何を目的として重みを更新指定行くかを決定している部分になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.11 エポック数は「4」、バッチサイズは「100」、validation_splitを「0.2」に設定して学習を開始して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.12 「学習データ(acc)」、「検証データ(val_acc)」の精度をエポック毎にグラフを表示して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.13 学習データ・検証データに対して約80％以上の正解率があるようです。「5.12」で作成したモデルで（X_train[1]）に対して予測結果を出力してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.14 悪いレビューである可能性が高そうです。事前準備「5.0」を利用してレビュー内容を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.15 実際の正解データを確認していきましょう。y_train[1]のラベルを確認して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
